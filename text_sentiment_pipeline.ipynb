{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819eb130-0852-4116-bd16-7f85d6ee7522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.2.2)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.7/791.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow, propcache, multidict, hf-xet, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [datasets]/19\u001b[0m [datasets]ers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 async-timeout-5.0.1 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 hf-xet-1.2.0 huggingface-hub-0.36.0 multidict-6.7.0 multiprocess-0.70.18 propcache-0.4.1 pyarrow-22.0.0 regex-2025.11.3 safetensors-0.7.0 tokenizers-0.22.1 transformers-4.57.3 xxhash-3.6.0 yarl-1.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7304f6ee-2854-4b89-a619-15d9643bada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61c5a0a-a766-4aa7-8d33-93356361fb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    # positive\n",
    "    (\"I love this movie, it was amazing!\", \"positive\"),\n",
    "    (\"This song makes me happy.\", \"positive\"),\n",
    "    (\"The food was really good, I enjoyed it.\", \"positive\"),\n",
    "    (\"I had a great day today.\", \"positive\"),\n",
    "    (\"The lecture was clear and helpful.\", \"positive\"),\n",
    "    (\"I feel satisfied with the result.\", \"positive\"),\n",
    "    (\"The new update is actually pretty nice.\", \"positive\"),\n",
    "    (\"My friend was so kind to me today.\", \"positive\"),\n",
    "    (\"The weather is beautiful and I like it.\", \"positive\"),\n",
    "    (\"This app is very useful and easy to use.\", \"positive\"),\n",
    "    (\"The cafe was cozy and the staff were friendly.\", \"positive\"),\n",
    "    (\"I didn’t expect much, but it turned out great.\", \"positive\"),\n",
    "    (\"The presentation went better than I thought.\", \"positive\"),\n",
    "    (\"I’m proud of what I did today.\", \"positive\"),\n",
    "    (\"The service was slow, but overall I’m satisfied.\", \"positive\"),\n",
    "    (\"It wasn’t perfect, but I still enjoyed it.\", \"positive\"),\n",
    "    (\"The game was fun and exciting.\", \"positive\"),\n",
    "    (\"I feel calm right now.\", \"positive\"),\n",
    "    (\"The new feature is surprisingly helpful.\", \"positive\"),\n",
    "    (\"Even though I was tired, the day felt rewarding.\", \"positive\"),\n",
    "\n",
    "    # negative\n",
    "    (\"I hate this movie, it was terrible.\", \"negative\"),\n",
    "    (\"This is the worst experience ever.\", \"negative\"),\n",
    "    (\"The food tasted bad and disgusting.\", \"negative\"),\n",
    "    (\"I am really disappointed with the service.\", \"negative\"),\n",
    "    (\"Today was such a horrible day.\", \"negative\"),\n",
    "    (\"The lecture was boring and confusing.\", \"negative\"),\n",
    "    (\"I feel so upset about the result.\", \"negative\"),\n",
    "    (\"The new update is really annoying.\", \"negative\"),\n",
    "    (\"My friend ignored me and I feel bad.\", \"negative\"),\n",
    "    (\"The weather is awful and I hate it.\", \"negative\"),\n",
    "    (\"I thought it would be good, but it was actually bad.\", \"negative\"),\n",
    "    (\"The app keeps crashing, it’s frustrating.\", \"negative\"),\n",
    "    (\"It wasn’t the worst, but I can’t say I liked it.\", \"negative\"),\n",
    "    (\"The more I use this, the more disappointed I feel.\", \"negative\"),\n",
    "    (\"I’m tired and nothing went well today.\", \"negative\"),\n",
    "    (\"The staff were rude and unhelpful.\", \"negative\"),\n",
    "    (\"I tried to enjoy it, but I just couldn’t.\", \"negative\"),\n",
    "    (\"The result is far from what I expected.\", \"negative\"),\n",
    "    (\"I feel anxious and unhappy about this.\", \"negative\"),\n",
    "    (\"Even though some parts were okay, overall it was bad.\", \"negative\"),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa78d65-97b0-49bd-97cb-1f8c53e00030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "def rule_based_sentiment(text: str) -> str:\n",
    "    t = text.lower()\n",
    "\n",
    "    positive_keywords = [\"love\", \"happy\", \"amazing\", \"great\", \"good\", \"nice\", \"satisfied\", \"beautiful\", \"useful\", \"kind\", \"enjoyed\", \"helpful\"]\n",
    "    negative_keywords = [\"hate\", \"worst\", \"terrible\", \"bad\", \"disappointed\", \"horrible\", \"boring\", \"upset\", \"annoying\", \"awful\", \"disgusting\", \"ignored\"]\n",
    "\n",
    "    # count how many positive/negative words appear\n",
    "    pos_score = sum(kw in t for kw in positive_keywords)\n",
    "    neg_score = sum(kw in t for kw in negative_keywords)\n",
    "\n",
    "    if pos_score > neg_score:\n",
    "        return \"positive\"\n",
    "    elif neg_score > pos_score:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        # default guess when it's unclear\n",
    "        return \"negative\"\n",
    "\n",
    "# test\n",
    "print(rule_based_sentiment(\"I love this movie but the ending was bad\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71609c3-8a00-4b5e-a997-984d7fffbabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df[\"text\"].tolist()\n",
    "true_labels = df[\"label\"].tolist()\n",
    "\n",
    "baseline_preds = [rule_based_sentiment(t) for t in texts]\n",
    "baseline_acc = accuracy_score(true_labels, baseline_preds)\n",
    "\n",
    "baseline_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ba67ee-91ee-48ab-8482-d6671920b398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbef211c91e14527b1314c05121db193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73948095ac2f4c43a3564e1d14273612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f45b88c8cd436f910f5741694e34b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2917daa145140fd95ec77b343647620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c01798-cfd0-4429-abd2-8ace9c7ced64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998791217803955},\n",
       " {'label': 'POSITIVE', 'score': 0.9998822212219238},\n",
       " {'label': 'POSITIVE', 'score': 0.9998779296875},\n",
       " {'label': 'POSITIVE', 'score': 0.9998636245727539},\n",
       " {'label': 'POSITIVE', 'score': 0.9997597336769104}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model on all texts\n",
    "hf_outputs = sentiment_model(df[\"text\"].tolist())\n",
    "\n",
    "# Show the first few results\n",
    "hf_outputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bbfd7bb-e7ae-45f4-b8cd-b4ba182543fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hf_label_to_simple(label: str) -> str:\n",
    "    return \"positive\" if label.upper() == \"POSITIVE\" else \"negative\"\n",
    "\n",
    "hf_preds = [hf_label_to_simple(o[\"label\"]) for o in hf_outputs]\n",
    "\n",
    "hf_acc = accuracy_score(df[\"label\"], hf_preds)\n",
    "hf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4368b2f9-d8d3-4527-965a-b8695daeab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.8\n",
      "AI pipeline accuracy: 1.0\n",
      "\n",
      "Examples where baseline and AI differ:\n",
      "\n",
      "TEXT: The cafe was cozy and the staff were friendly.\n",
      "TRUE LABEL: positive\n",
      "BASELINE: negative\n",
      "AI MODEL: positive\n",
      "------------------------------------------------------------\n",
      "TEXT: The presentation went better than I thought.\n",
      "TRUE LABEL: positive\n",
      "BASELINE: negative\n",
      "AI MODEL: positive\n",
      "------------------------------------------------------------\n",
      "TEXT: I’m proud of what I did today.\n",
      "TRUE LABEL: positive\n",
      "BASELINE: negative\n",
      "AI MODEL: positive\n",
      "------------------------------------------------------------\n",
      "TEXT: The game was fun and exciting.\n",
      "TRUE LABEL: positive\n",
      "BASELINE: negative\n",
      "AI MODEL: positive\n",
      "------------------------------------------------------------\n",
      "TEXT: I feel calm right now.\n",
      "TRUE LABEL: positive\n",
      "BASELINE: negative\n",
      "AI MODEL: positive\n",
      "------------------------------------------------------------\n",
      "TEXT: Even though I was tired, the day felt rewarding.\n",
      "TRUE LABEL: positive\n",
      "BASELINE: negative\n",
      "AI MODEL: positive\n",
      "------------------------------------------------------------\n",
      "TEXT: The staff were rude and unhelpful.\n",
      "TRUE LABEL: negative\n",
      "BASELINE: positive\n",
      "AI MODEL: negative\n",
      "------------------------------------------------------------\n",
      "TEXT: I feel anxious and unhappy about this.\n",
      "TRUE LABEL: negative\n",
      "BASELINE: positive\n",
      "AI MODEL: negative\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline accuracy:\", baseline_acc)\n",
    "print(\"AI pipeline accuracy:\", hf_acc)\n",
    "print()\n",
    "\n",
    "print(\"Examples where baseline and AI differ:\\n\")\n",
    "for text, true, base, hf in zip(df[\"text\"], df[\"label\"], baseline_preds, hf_preds):\n",
    "    if base != hf:\n",
    "        print(\"TEXT:\", text)\n",
    "        print(\"TRUE LABEL:\", true)\n",
    "        print(\"BASELINE:\", base)\n",
    "        print(\"AI MODEL:\", hf)\n",
    "        print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bce48b-afe7-42f2-98d1-a4336999b113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
